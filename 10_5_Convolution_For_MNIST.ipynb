{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andres4ramos/167/blob/main/10_5_Convolution_For_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Notebook 10.5: Convolution for MNIST**\n",
        "\n",
        "This notebook builds a proper network for 2D convolution.  It works with the MNIST dataset (figure 15.15a), which was the original classic dataset for classifying images.  The network will take a 28x28 grayscale image and classify it into one of 10 classes representing a digit.\n",
        "\n",
        "The code is adapted from https://nextjournal.com/gkoehler/pytorch-mnist\n",
        "\n",
        "Work through the cells below, running each cell in turn. In various places you will see the words \"TO DO\". Follow the instructions at these places and make predictions about what is going to happen or write code to complete the functions.\n",
        "\n",
        "Contact me at udlbookmail@gmail.com if you find any mistakes or have any suggestions.\n"
      ],
      "metadata": {
        "id": "t9vk9Elugvmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "YrXWAH7sUWvU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Set batch sizes for training and test data\n",
        "batch_size_train = 64\n",
        "batch_size_test = 1000\n",
        "\n",
        "# Directory to save/download the MNIST data\n",
        "myDir = '/files/'  # Change this path to a valid directory on your machine if necessary\n",
        "\n",
        "# Define transformations: Convert to tensor and normalize data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize with mean and std of MNIST dataset\n",
        "])\n",
        "\n",
        "# Load training data\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST(\n",
        "        myDir, train=True, download=True, transform=transform\n",
        "    ),\n",
        "    batch_size=batch_size_train,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Load test data\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST(\n",
        "        myDir, train=False, download=True, transform=transform\n",
        "    ),\n",
        "    batch_size=batch_size_test,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Check data loading\n",
        "for (images, labels) in train_loader:\n",
        "    print(f\"Batch size: {images.size()}, Labels: {labels.size()}\")\n",
        "    break\n"
      ],
      "metadata": {
        "id": "wScBGXXFVadm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16d0fb29-5d7f-4c4e-e51f-d991bf618718"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: torch.Size([64, 1, 28, 28]), Labels: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's draw some of the training data\n",
        "examples = enumerate(test_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8bKADvLHbiV5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "8c3945f3-84f4-42ce-9cdc-e7b52b9df0b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAGlCAYAAABQuDoNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwoklEQVR4nO3deVyVZd7H8d9BVAQBEbEkFXfcRi2XbHFpJpd0NCx3LU3xebmUuWUu9YhlDqahYmLLzIOl2fBUbuOYY4+NY9trbJkyx4cKQ0fFlHEBAnPjev7wgTpy3XJuuA/nOvB5v17+wfecc9+/g+enP+5zLi6XUkoJAAAAfC7A1wUAAADgGgYzAAAAQzCYAQAAGILBDAAAwBAMZgAAAIZgMAMAADAEgxkAAIAhGMwAAAAMwWAGAABgCAYzL3K5XJKQkODrMm5o/PjxUrt2bV+XAXiEngKcR1+ZxeeDWWZmpjz66KPSqlUrCQ4OluDgYGnbtq1MmzZNDhw44OvyvKp3797icrlK/VPehikoKJCEhATZu3evI3V7avv27XLbbbdJUFCQNG7cWBYtWiRXrlyp0BqqInqq8vXUmTNnZPny5dKzZ0+JioqSOnXqSPfu3SUtLa1Czg/6qjL2lYhIkyZNtM9l8uTJFVbD9QJ9dmYR2bFjh4wYMUICAwNlzJgx0rFjRwkICJD09HTZvHmzrFu3TjIzMyUmJsaXZXrNwoULJT4+vvjrTz/9VJKTk2XBggXSpk2b4rxDhw7lOk9BQYEsXrxYRK41WEV49913JS4uTnr37i1r1qyRr7/+WpYsWSKnT5+WdevWVUgNVRE9VTl76pNPPpGFCxfKgAED5KmnnpLAwEB55513ZOTIkXLo0KHiWuAd9FXl7KsinTp1ktmzZ7tlrVq1qrDzX89ng9nhw4dl5MiREhMTI3v27JEGDRq43b5s2TJJSUmRgIAbX9TLz8+XkJAQb5bqNX369HH7OigoSJKTk6VPnz43fFH6w3OeM2eOdOjQQXbv3i2BgddeZmFhYbJ06VJ5/PHHpXXr1j6usPKhpypvT7Vr106+++47t//4p06dKvfee68sW7ZM5s6da3T9/oy+qrx9VeSWW26RsWPH+rqMYj57K/P555+X/Px8SU1NLfFCFxEJDAyU6dOnS6NGjYqzoveYDx8+LAMGDJDQ0FAZM2aMiFx7AcyePVsaNWokNWvWlNjYWFmxYoUopYoff+TIEXG5XLJ+/foS57v+MmxCQoK4XC7JyMiQ8ePHS506dSQ8PFweeeQRKSgocHvsxYsXZebMmRIVFSWhoaEyePBgOX78eDm/Q+51HDp0SEaPHi0RERFy9913i8i1nyh0TTF+/Hhp0qRJ8XOOiooSEZHFixdbXnI+ceKExMXFSe3atSUqKkrmzJkjV69edbvPyZMnJT09XS5fvnzDmg8dOiSHDh2S//iP/ygeykSu/UeilJK3337b5ncBnqCnPOOPPdW0adMSV2NcLpfExcXJxYsX5fvvv7fxHYAd9JVn/LGvfunSpUuSn5/v+RP2Ip8NZjt27JAWLVrI7bffbutxV65ckX79+kn9+vVlxYoV8uCDD4pSSgYPHiwrV66U/v37S1JSksTGxsoTTzwhs2bNKledw4cPl7y8PPnd734nw4cPl/Xr15d42yA+Pl5WrVolffv2lcTERKlevboMHDiwXOe93rBhw6SgoECWLl0qkyZN8vhxUVFRxW8dDhkyRDZs2CAbNmyQBx54oPg+V69elX79+klkZKSsWLFCevXqJS+88IK88sorbseaP3++tGnTRk6cOHHDc/7jH/8QEZEuXbq45dHR0dKwYcPi2+Esesoef+opKz/88IOIiNSrV69Mj0fp6Ct7/LGv3n//fQkODpbatWtLkyZNZPXq1R7X7RXKB3JycpSIqLi4uBK3nTt3TmVnZxf/KSgoKL5t3LhxSkTUvHnz3B6zdetWJSJqyZIlbvnQoUOVy+VSGRkZSimlMjMzlYio1NTUEucVEbVo0aLirxctWqRERE2YMMHtfkOGDFGRkZHFX3/55ZdKRNTUqVPd7jd69OgSxyzNW2+9pURE/fWvfy1Rx6hRo0rcv1evXqpXr14l8nHjxqmYmJjir7Ozsy1rKfqePvPMM275rbfeqjp37qy9b2Zm5g2fx/Lly5WIqH/9618lbuvatavq3r37DR8P++gpvcrSUzpnzpxR9evXVz169LD9WHiGvtKrTH01aNAgtWzZMrV161b1hz/8QfXo0UOJiJo7d26pj/UWn1wxy83NFRHRLn3t3bu3REVFFf9Zu3ZtiftMmTLF7eudO3dKtWrVZPr06W757NmzRSkl7777bplrvX5lRo8ePeTMmTPFz2Hnzp0iIiXOPWPGjDKf05M6nKZ7nte/PbJ+/XpRShVferZy4cIFERGpWbNmiduCgoKKb4dz6Kny1+E0J3vqeoWFhTJmzBg5f/68rFmzprylwgJ9Vf46nOZ0X23fvl3mzp0r999/v0yYMEH+9re/Sb9+/SQpKcmxt3nt8slgFhoaKiIiP/74Y4nbXn75ZXnvvfdk48aN2scGBgZKw4YN3bKjR49KdHR08XGLFK0WOXr0aJlrbdy4sdvXERERIiJy7ty54mMHBARI8+bN3e4XGxtb5nPqNG3a1NHj/VJQUFDxe/tFIiIiip+jXbVq1RKRa59nuN5PP/1UfDucQ0/Z5089db3HHntMdu3aJb///e+lY8eOjhwTJdFX9vlzX4lc+wzfzJkz5cqVKxX+K6aK+GRVZnh4uDRo0EAOHjxY4rai9/GPHDmifWzNmjVLXf1ixeVyafPrPzj4S9WqVdPm6hcf1KwIumHG5XJp67jR89Gxeo5lVfQB2ZMnT7p9ILYo69atm6PnAz1VFv7UU7+0ePFiSUlJkcTERHnooYe8dh7QV2Xhr331S0X/b509e7ZCznc9n334f+DAgZKRkSH79+8v97FiYmIkKytL8vLy3PL09PTi20V+/gni/Pnzbvcrz08pMTExUlhYKIcPH3bLv/nmmzIf01MRERElnotIyedj1eTe0qlTJxER+eyzz9zyrKwsOX78ePHtcBY9VX6m9lSRtWvXSkJCgsyYMUOefPJJn9RQ1dBX5Wd6X12v6K3R66/OVRSfDWZz586V4OBgmTBhgpw6darE7Xam/AEDBsjVq1flxRdfdMtXrlwpLpdL7rvvPhG59nu06tWrJ/v27XO7X0pKShmewTVFx05OTnbLV61aVeZjeqp58+aSnp4u2dnZxdlXX30lH330kdv9goODRaRkk9vl6RLkdu3aSevWreWVV15x+4lo3bp14nK5ZOjQoeWqA3r0VPmZ2lMiImlpaTJ9+nQZM2aMJCUlleu88Bx9VX6m9tXZs2dLXLW7fPmyJCYmSo0aNeSee+4pVx1l5bNfMNuyZUvZtGmTjBo1SmJjY4t/m7JSSjIzM2XTpk0SEBBQ4j16nUGDBsk999wjCxculCNHjkjHjh1l9+7dsm3bNpkxY4bbe+rx8fGSmJgo8fHx0qVLF9m3b598++23ZX4enTp1klGjRklKSork5OTInXfeKXv27JGMjIwyH9NTEyZMkKSkJOnXr59MnDhRTp8+LS+99JK0a9eu+AOfItcuLbdt21bS0tKkVatWUrduXWnfvr20b9/e1vnmz58vr732mmRmZpb6ocrly5fL4MGDpW/fvjJy5Eg5ePCgvPjiixIfH+/2m6LhHHqq/Eztqf3798vDDz8skZGR8pvf/EbeeOMNt9vvvPNOadasma1zwzP0VfmZ2lfbt2+XJUuWyNChQ6Vp06Zy9uxZ2bRpkxw8eFCWLl0qN998c1mfcvlU9DLQ62VkZKgpU6aoFi1aqKCgIFWrVi3VunVrNXnyZPXll1+63XfcuHEqJCREe5y8vDw1c+ZMFR0drapXr65atmypli9frgoLC93uV1BQoCZOnKjCw8NVaGioGj58uDp9+rTlEuTs7Gy3x6emppZYhnvhwgU1ffp0FRkZqUJCQtSgQYPUsWPHHF2CfH0dRTZu3KiaNWumatSooTp16qT+8pe/lFiCrJRSH3/8sercubOqUaOGW11W39Oi8/6S3aX9W7ZsUZ06dVI1a9ZUDRs2VE899ZS6dOmSR49F2dFTP6ssPVX0PbL6o/u1CnAWffWzytJXn332mRo0aJC65ZZbVI0aNVTt2rXV3Xffrf77v/+71O+BN7mUquBPBgIAAEDLZ58xAwAAgDsGMwAAAEMwmAEAABiCwQwAAMAQDGYAAACGYDADAAAwhEe/YLawsFCysrIkNDTUmC0TAJFrv3U7Ly9PoqOjy7wvna/QVzAVfQU4z9O+8mgwy8rKKrEZNWCSY8eOefSbt01CX8F09BXgvNL6yqMfhUJDQx0rCPAGf3yN+mPNqFr88TXqjzWjaintNerRYMblYJjOH1+j/lgzqhZ/fI36Y82oWkp7jfrXhwcAAAAqMQYzAAAAQzCYAQAAGILBDAAAwBAMZgAAAIZgMAMAADAEgxkAAIAhGMwAAAAMwWAGAABgCAYzAAAAQzCYAQAAGILBDAAAwBAMZgAAAIZgMAMAADBEoK8LAADT1KhRQ5unpqZq89GjR9s6fmhoqDb/8ccfbR0HQOXDFTMAAABDMJgBAAAYgsEMAADAEAxmAAAAhmAwAwAAMASrMgFUeoGB+n/qZs6cqc3nz5+vzevUqaPNlVLa/PLly7buDwBcMQMAADAEgxkAAIAhGMwAAAAMwWAGAABgCAYzAAAAQ7AqE4DfsdrL0moPysTERG0+ceJER+r56aeftPmQIUO0eX5+viPnRdVitSo4Pj5emycnJ2vzS5cu2TpvkyZNtPn777+vzZs2bWrr+N62cuVKbW61N+0nn3yizXft2qXNnV5lzRUzAAAAQzCYAQAAGILBDAAAwBAMZgAAAIZgMAMAADAEqzIB+JzVKsvIyEhtvmDBAm0+bdo0x2qyIy0tTZu/9957FVwJKgOXy6XNn3/+eW1utbrYarVm69attbnV6kur13FMTIw2Lyws1Oa+8vjjjztynKCgIG1utSduWXHFDAAAwBAMZgAAAIZgMAMAADAEgxkAAIAhGMwAAAAMUeVXZXbr1k2bDxgwQJufP39em4eFhWlzq9U1Vv74xz9q85EjR9o6jl3r1q3T5lbP1+5ea4CI9SquNWvWaPPf/va33izHMePGjdPms2fP1uZnz571Zjnwc3Xr1tXmTu3tamXx4sXa/Oabb9bmvnodW63irl27tjY/d+6cNrfae/TPf/6zNq+o1aZcMQMAADAEgxkAAIAhGMwAAAAMwWAGAABgCAYzAAAAQ1T5VZmdO3fW5k8//bQ2nzVrlja///77tbnVqsaDBw9q823btmnzL774QpsPHz5cm1uZM2eONj958qQ2Hzt2rDZ/8803bZ0XELFeVebU6sv8/HxtnpWVZes4VnsGVq9e3dZxrP5dSE1NtXUcVC333XefT85rtbrYatX0Z5995s1yLMXGxmrzX//619r8tdde0+YjRozQ5hs3btTmV69e9aC68uOKGQAAgCEYzAAAAAzBYAYAAGAIBjMAAABDMJgBAAAYosqsyrTaE3PBggW2jvPCCy9o82HDhmnzLVu22Dp+SkqKNp83b542P378uDZv3ry5Np86daoj9ezatUubW+1JBoiI/OpXv7J1f6tVlu+//742X758uTb/8MMPbZ33o48+0uZ33HGHreNY7TEIiIgEBQVp87lz5zpyfKtVxFarji9evKjNfbX60so333xjK7di6uporpgBAAAYgsEMAADAEAxmAAAAhmAwAwAAMASDGQAAgCGqzKrM/v37a/Po6GhtfurUKW1+5swZbe7U6iurVZC5ubna/O2339bmVs9r69at2vy7777T5s2aNdPmixYt0uYzZszQ5oCI9Z51jRo10ubJycna/PXXX3esJh2rPWvtrsp8+eWXnSgHldTQoUO1ebt27Rw5vtXqy8OHD2vzs2fPavNXX31Vm69bt06bHzt2rPTiYIkrZgAAAIZgMAMAADAEgxkAAIAhGMwAAAAMwWAGAABgCJdSSpV2p9zcXAkPD6+IerwmLS1Nmz/44IPaPCYmRpufOHHCsZpMYrUqbv/+/dq8Tp062vzRRx/V5n//+9+1+cGDB0svzgM5OTkSFhbmyLEqSmXoK39Xr149bf7FF19o84YNGzpyfKvVb6ahr7xrzpw52nzZsmUVXEnZZGdna/PevXtr8/T0dC9W4z9K6yuumAEAABiCwQwAAMAQDGYAAACGYDADAAAwBIMZAACAISrdXplWq6Datm2rzadNm6bNK+vqSytWe5v97//+rzbv2bOnNh89erQ2/8Mf/lC2wgAvmjBhgja3u/ryT3/6kzbPy8uzXROqDqu9ka1Wa0ZFRXmzHNus6pk6dao2nz59ujfLqTS4YgYAAGAIBjMAAABDMJgBAAAYgsEMAADAEAxmAAAAhqh0qzK3bdumza22BH3zzTe9WQ7+X7du3bS51V6cgJPGjRunzZ9++mlHjr9v3z5tfvnyZUeOj8qpoKBAmw8cOFCbJycna/OcnBxtvmbNGlv1jB8/XpsPHTrU1nFGjBihzdeuXavNv/nmG1vHr+y4YgYAAGAIBjMAAABDMJgBAAAYgsEMAADAEAxmAAAAhvDbVZmpqanavEuXLtr8ww8/1Oa5ubmO1eTP4uLitLnV99Muq70yf/WrXzlyfEBEpH79+trcavVlSEiIreMnJSVpc7ur34Ab+fzzz7X5XXfd5dXzfvTRR9q8cePG2txqtb3VntVWe1Ozh6Y7rpgBAAAYgsEMAADAEAxmAAAAhmAwAwAAMASDGQAAgCGMX5UZFBSkzdu2bavNXS6XNl+2bJljNfmzunXravMtW7Zo88LCQm2+c+dObW61+vLZZ5/1oDpUdnXq1NHmr7zyijZv0aKFreOHhYVp82bNmtk6jhWrvQovXbrkyPEBX7L6LQUrV67U5nb3mh41apQ2t+qrjIwMW8evLLhiBgAAYAgGMwAAAEMwmAEAABiCwQwAAMAQDGYAAACGMH5VZvPmzbV5586dtXl2drY23717t2M1maRdu3bafMaMGdq8R48e2txq9eXevXu1+RNPPKHN09PTtbnV3xf8g9WekoMGDdLmUVFR2vzxxx/X5k6tmgTgvAMHDmjzf//739rcaq9Mq98KYLVXZlXdQ5MrZgAAAIZgMAMAADAEgxkAAIAhGMwAAAAMwWAGAABgCONXZbZp00abX758uYIrqRiBgfq/kkceeUSbW+091rNnT21+4cIFbX7zzTdr8/Pnz2tzu9//pUuX2ro/fOP222/X5k8++aQ2j4uL82I15rFapTxp0iRtvmfPHi9WA1QMq9X2aWlp2nzatGm2jh8dHW27psqMK2YAAACGYDADAAAwBIMZAACAIRjMAAAADMFgBgAAYAjjV2UOGzZMm+fk5FRwJWVjtZflPffco81jYmK0+cyZM22d99ChQ9r84Ycf1uZWe4w6xWo1KHzD6vW3bds2bV67dm1vluM3mjRpos0feOABbc6qTIiIVKtWTZuvW7dOm1vtQblgwQLHanLCO++8o83trsps2LChNg8PD9fm/vL/f1lxxQwAAMAQDGYAAACGYDADAAAwBIMZAACAIRjMAAAADGH8qsyhQ4dqc6WUNv/xxx+1efPmzbX54cOHtXndunW1efv27bX5Cy+8oM1btGihzUNDQ7W5y+XS5hkZGdrcahXd2rVrtfnRo0e1OSqnGjVqaPOnn35am/vL6svjx49r86SkJG3+xz/+UZtbrZp+++23tbnVKjHgRqz2QJ44caI2t/p/zGrPyo8//libW/2/4ZT9+/dr888++0ybd+nSRZt37dpVm1ut1mRVJgAAACoEgxkAAIAhGMwAAAAMwWAGAABgCAYzAAAAQxi/KnPp0qXa3GrPMKvVjnv37tXmtWrV0uZWqzKtVoPade7cOW2+aNEibb5161ZtfuLECUfqQeVUs2ZNbd67d++KLaSMNm/erM2t+uSf//ynreP/8MMP2txqT0yr79v//M//2DovqparV69q8wMHDmjzDh06aPPU1FRtfvbsWW1utRfnf/7nf2pzu6z2QGZv5PLhihkAAIAhGMwAAAAMwWAGAABgCAYzAAAAQzCYAQAAGML4VZmJiYnaPCQkRJtPnjxZmzdo0MDWea1WX1rtPWa1GiwzM1ObW62W8fbeZoCJVq9erc3nzJmjza1WuTnFai8+q71pgRu5cuWKNl+8eLE2t1p1bLVa0+q3CMybN0+bR0REaPMNGzZo886dO2vzsWPH2ro/PMMVMwAAAEMwmAEAABiCwQwAAMAQDGYAAACGYDADAAAwhEt5sPljbm6uhIeHV0Q95da/f39t3q1bN1vHcblc2vzNN9/U5larKQsLC22dF2WTk5MjYWFhvi7DloroK6u9MpcsWaLNZ8+e7ch5rfa4TEhI0OaHDh3S5vSPb9FXvhEZGanNrfZktVqtaddPP/2kzYOCghw5vl1Wz8vunrimKa2vuGIGAABgCAYzAAAAQzCYAQAAGILBDAAAwBAMZgAAAIaodKsyUTWxegxwHn1lFl+t1nTK999/r82tfpuC1V7T/r5am1WZAAAAfoLBDAAAwBAMZgAAAIZgMAMAADAEgxkAAIAhAn1dAAAAKN2ZM2e0edeuXbV5vXr1tPmUKVO0+bBhw7R5bGysNv/Xv/6lzRcvXqzNN27cqM2vXLmizasqrpgBAAAYgsEMAADAEAxmAAAAhmAwAwAAMASDGQAAgCHYKxOVAnv6Ac6jrwDnsVcmAACAn2AwAwAAMASDGQAAgCEYzAAAAAzBYAYAAGAIBjMAAABDMJgBAAAYgsEMAADAEAxmAAAAhmAwAwAAMASDGQAAgCEYzAAAAAzBYAYAAGAIBjMAAABDMJgBAAAYgsEMAADAEB4NZkopb9cBlIs/vkb9sWZULf74GvXHmlG1lPYa9Wgwy8vLc6QYwFv88TXqjzWjavHH16g/1oyqpbTXqEt58ONFYWGhZGVlSWhoqLhcLseKA8pLKSV5eXkSHR0tAQH+9c48fQVT0VeA8zztK48GMwAAAHiff/0oBAAAUIkxmAEAABiCwQwAAMAQDGYAAACGYDADAAAwBIMZAACAIRjMAAAADMFgBgAAYAgGMwAAAEMwmAEAABiCwQwAAMAQDGYAAACGYDADAAAwBIMZAACAIRjMAAAADMFgBgAAYAgGMwAAAEMwmAEAABiCwQwAAMAQDGYAAACGYDDzIpfLJQkJCb4u44bGjx8vtWvX9nUZgEfoKcB59JVZfD6YZWZmyqOPPiqtWrWS4OBgCQ4OlrZt28q0adPkwIEDvi7Pq3r37i0ul6vUP+VtmIKCAklISJC9e/c6Urcn0tLSZOzYsdKyZUtxuVzSu3fvCjt3VUdPVb6eOnPmjCxfvlx69uwpUVFRUqdOHenevbukpaVVyPlBX1XGvtq7d+8Nn89zzz1XIXVcL9AnZ/1/O3bskBEjRkhgYKCMGTNGOnbsKAEBAZKeni6bN2+WdevWSWZmpsTExPiyTK9ZuHChxMfHF3/96aefSnJysixYsEDatGlTnHfo0KFc5ykoKJDFixeLiFTYgLRu3Tr5/PPPpWvXrnLmzJkKOSfoqcraU5988oksXLhQBgwYIE899ZQEBgbKO++8IyNHjpRDhw4V1wLvoK8qZ1+1adNGNmzYUCLfsGGD7N69W/r27ev1GnR8NpgdPnxYRo4cKTExMbJnzx5p0KCB2+3Lli2TlJQUCQi48UW9/Px8CQkJ8WapXtOnTx+3r4OCgiQ5OVn69OlzwxelPzznDRs2yC233CIBAQHSvn17X5dTJdBTlben2rVrJ999953bf/xTp06Ve++9V5YtWyZz5841un5/Rl9V3r666aabZOzYsSXyxYsXS8uWLaVr164+qMqHb2U+//zzkp+fL6mpqSVe6CIigYGBMn36dGnUqFFxVvQe8+HDh2XAgAESGhoqY8aMEZFrL4DZs2dLo0aNpGbNmhIbGysrVqwQpVTx448cOSIul0vWr19f4nzXX4ZNSEgQl8slGRkZMn78eKlTp46Eh4fLI488IgUFBW6PvXjxosycOVOioqIkNDRUBg8eLMePHy/nd8i9jkOHDsno0aMlIiJC7r77bhG59hOFrinGjx8vTZo0KX7OUVFRInLtxWZ1yfnEiRMSFxcntWvXlqioKJkzZ45cvXrV7T4nT56U9PR0uXz5cql1N2rUqNR/qOAsesoz/thTTZs2LXE1xuVySVxcnFy8eFG+//57G98B2EFfecYf+0pn//79kpGRUfz35Qs++59zx44d0qJFC7n99tttPe7KlSvSr18/qV+/vqxYsUIefPBBUUrJ4MGDZeXKldK/f39JSkqS2NhYeeKJJ2TWrFnlqnP48OGSl5cnv/vd72T48OGyfv36Em8bxMfHy6pVq6Rv376SmJgo1atXl4EDB5brvNcbNmyYFBQUyNKlS2XSpEkePy4qKkrWrVsnIiJDhgyRDRs2yIYNG+SBBx4ovs/Vq1elX79+EhkZKStWrJBevXrJCy+8IK+88orbsebPny9t2rSREydOOPOk4Ch6yp7K0FM//PCDiIjUq1evTI9H6egre/y9r9544w0REZ8OZqJ8ICcnR4mIiouLK3HbuXPnVHZ2dvGfgoKC4tvGjRunRETNmzfP7TFbt25VIqKWLFnilg8dOlS5XC6VkZGhlFIqMzNTiYhKTU0tcV4RUYsWLSr+etGiRUpE1IQJE9zuN2TIEBUZGVn89ZdffqlERE2dOtXtfqNHjy5xzNK89dZbSkTUX//61xJ1jBo1qsT9e/XqpXr16lUiHzdunIqJiSn+Ojs727KWou/pM88845bfeuutqnPnztr7ZmZmevyclFKqXbt22jrhHHpKr7L2lFJKnTlzRtWvX1/16NHD9mPhGfpKr7L21ZUrV9RNN92kunXrZutxTvPJFbPc3FwREe3S1969e0tUVFTxn7Vr15a4z5QpU9y+3rlzp1SrVk2mT5/uls+ePVuUUvLuu++WudbJkye7fd2jRw85c+ZM8XPYuXOniEiJc8+YMaPM5/SkDqfpnuf1b4+sX79elFLFl55hDnqq/HU4zZs9VVhYKGPGjJHz58/LmjVrylsqLNBX5a/Dad7sqz179sipU6d8e7VMfPTh/9DQUBER+fHHH0vc9vLLL0teXp6cOnVK+6G8wMBAadiwoVt29OhRiY6OLj5ukaLVIkePHi1zrY0bN3b7OiIiQkREzp07J2FhYXL06FEJCAiQ5s2bu90vNja2zOfUadq0qaPH+6WgoKDi9/aLREREyLlz57x2TjiLnrLPn3vqsccek127dsnrr78uHTt2dOSYKIm+ss+f++qNN96QatWqyYgRIxw5Xln5ZDALDw+XBg0ayMGDB0vcVvQ+/pEjR7SPrVmzZpk/VO5yubT59R8c/KVq1appc/WLD2pWhFq1apXIXC6Xto4bPR8dq+cI/0FP2eevPbV48WJJSUmRxMREeeihh7x2HtBXZeGvfXXhwgXZsmWL3HvvvXLTTTd57Tye8NmH/wcOHCgZGRmyf//+ch8rJiZGsrKyJC8vzy1PT08vvl3k558gzp8/73a/8vyUEhMTI4WFhXL48GG3/JtvvinzMT0VERFR4rmIlHw+Vk2OyoWeKj/Te2rt2rWSkJAgM2bMkCeffNInNVQ19FX5md5XIiLbt2+XvLw8n7+NKeLDwWzu3LkSHBwsEyZMkFOnTpW43c6UP2DAALl69aq8+OKLbvnKlSvF5XLJfffdJyIiYWFhUq9ePdm3b5/b/VJSUsrwDK4pOnZycrJbvmrVqjIf01PNmzeX9PR0yc7OLs6++uor+eijj9zuFxwcLCIlm9yu8ixBhvfRU+Vnck+lpaXJ9OnTZcyYMZKUlFSu88Jz9FX5mdxXRTZt2iTBwcEyZMiQcp3bCT77BbMtW7aUTZs2yahRoyQ2Nrb4tykrpSQzM1M2bdokAQEBJd6j1xk0aJDcc889snDhQjly5Ih07NhRdu/eLdu2bZMZM2a4vaceHx8viYmJEh8fL126dJF9+/bJt99+W+bn0alTJxk1apSkpKRITk6O3HnnnbJnzx7JyMgo8zE9NWHCBElKSpJ+/frJxIkT5fTp0/LSSy9Ju3btij/wKXLt0nLbtm0lLS1NWrVqJXXr1pX27dvb/sWv8+fPl9dee00yMzNL/VDlvn37iv9Ryc7Olvz8fFmyZImIiPTs2VN69uxp78miVPRU+ZnaU/v375eHH35YIiMj5Te/+U3xkv4id955pzRr1szWueEZ+qr8TO2rImfPnpV3331XHnzwQTP246zoZaDXy8jIUFOmTFEtWrRQQUFBqlatWqp169Zq8uTJ6ssvv3S777hx41RISIj2OHl5eWrmzJkqOjpaVa9eXbVs2VItX75cFRYWut2voKBATZw4UYWHh6vQ0FA1fPhwdfr0acslyNnZ2W6PT01NLbEM98KFC2r69OkqMjJShYSEqEGDBqljx445ugT5+jqKbNy4UTVr1kzVqFFDderUSf3lL38psQRZKaU+/vhj1blzZ1WjRg23uqy+p0Xn/SU7S5CLHq/7Y+d7AvvoqZ9Vlp4q+h5Z/dH9WgU4i776WWXpqyIvvfSSEhG1fft2j+7vbS6lKviTgQAAANBizxwAAABDMJgBAAAYgsEMAADAEAxmAAAAhmAwAwAAMASDGQAAgCE8+gWzhYWFkpWVJaGhoWzvA6MopSQvL0+io6PLvC+dr9BXMBV9BTjP077yaDDLysqSRo0aOVYc4LRjx4559Ju3TUJfwXT0FeC80vrKox+FQkNDHSsI8AZ/fI36Y82oWvzxNeqPNaNqKe016tFgxuVgmM4fX6P+WDOqFn98jfpjzahaSnuN+teHBwAAACoxBjMAAABDMJgBAAAYgsEMAADAEAxmAAAAhmAwAwAAMASDGQAAgCEYzAAAAAzBYAYAAGAIBjMAAABDMJgBAAAYgsEMAADAEAxmAAAAhmAwAwAAMASDGQAAgCEYzAAAAAzBYAYAAGAIBjMAAABDMJgBAAAYgsEMAADAEIG+LgCe6dy5szafNGmSNp88ebI3ywFuKDQ0VJuPHTvW1nEaNGigzRcuXKjNAwL0P2sWFhbaOq+VgwcPavMVK1Zo8w0bNjhyXgBVB1fMAAAADMFgBgAAYAgGMwAAAEMwmAEAABiCwQwAAMAQLqWUKu1Oubm5Eh4eXhH1wMLf/vY3bX7XXXdp88DAqrXgNicnR8LCwnxdhi3+1FeNGjXS5q+//ro2r1+/vjaPjY11rCYdl8ulzT34Z65cLl26pM2XL1+uzZ999lltfuXKFcdqcgJ9BTivtL7iihkAAIAhGMwAAAAMwWAGAABgCAYzAAAAQzCYAQAAGKJqLd3zA1Z76/Xs2VObW+0BOGTIEG2+ZcuWshWGKiEyMlKbb926VZt37NhRm1u9LnNycspUl6esVmVarYLs37+/Nu/SpYs2t1rtHBISos2t9vQ8e/asNl+9erU2B1B1cMUMAADAEAxmAAAAhmAwAwAAMASDGQAAgCEYzAAAAAzBqkzDtG7dWptbrXI7dOiQNmf1Jcpi1apV2txq9WVGRoY2/6//+i9t/vzzz5epLm9ZuXKlrfsPHDhQm2/bts3WcR566CFt/s4772jz48eP2zo+/EP37t21+e7du7X5119/rc0//PBDW+e1ep1Z9bOV8+fPa3Or/6/gGa6YAQAAGILBDAAAwBAMZgAAAIZgMAMAADAEgxkAAIAhWJXpIzExMdq8cePG2jwgQD9Dt23b1rGaALuGDx+uzQ8cOFDBlVSM999/X5uvWbNGmz/22GPavFOnTtrc6t8FVmVWTi+99JI2r127tja/4447bOVWnnjiCVv3tzJz5kxtnpycrM2VUo6ct7LjihkAAIAhGMwAAAAMwWAGAABgCAYzAAAAQzCYAQAAGIJVmT4SHx+vzSMjI7W51d5jzz33nGM1AWvXrtXmd911lzYfOnSoNq+sqzIvXLigza323LRalWklIiLCdk3wXydPntTmHTp0qOBKysbuXrOrV6/2UiWVC1fMAAAADMFgBgAAYAgGMwAAAEMwmAEAABiCwQwAAMAQLuXB5lW5ubkSHh5eEfVUGVZ7pE2aNEmbW61mmTVrlmM1+bOcnBwJCwvzdRm2VIa+6tu3rzbfvXt3BVfiW1Z73H7//fe2jvP1119r81tvvdV2TU6gr7zrpptu0ubbtm3T5t26dfNmOY7Jz8/X5qGhoRVciZlK6yuumAEAABiCwQwAAMAQDGYAAACGYDADAAAwBIMZAACAIdgr00eGDBmizT1YJAsYo6qtvvS2Tz/91NcloAKdOnVKm//2t7/V5rfccos2DwkJ0ebTpk0rW2HXGThwoDa3WlkYGKgfLVq1aqXNv/3227IVVklxxQwAAMAQDGYAAACGYDADAAAwBIMZAACAIRjMAAAADMGqTC+zWn0ZFRWlza1WZbZp08axmgCY6bXXXvN1CTDAv//9b1u5lY8//tiJcqRBgwba/KuvvtLm9erV0+Z9+vTR5qzKdMcVMwAAAEMwmAEAABiCwQwAAMAQDGYAAACGYDADAAAwBKsyvWzBggXa3Gr1pVW+ZcsWx2oC4KxRo0b5ugTAa06ePKnNL1++XMGVVA1cMQMAADAEgxkAAIAhGMwAAAAMwWAGAABgCAYzAAAAQ7Aq0yExMTHavHHjxtq8oKBAmz/88MPanFWZ8CehoaHafOzYsY4cf9++fdr8n//8pyPHt2LV52PGjNHmLpfLm+UAPvXBBx9o8+HDh1dwJZULV8wAAAAMwWAGAABgCAYzAAAAQzCYAQAAGILBDAAAwBCsynRIvXr1tHlkZKQ2/8c//qHNWX0JXwoM1P+T0L17d23+7LPPavP69etr89jY2LIVdp2srCxtvm3bNm0+b948bZ6fn2/rvPfff782b9u2rTa32vs2OTlZm1v9uwCY6O9//7s2Z1Vm+XDFDAAAwBAMZgAAAIZgMAMAADAEgxkAAIAhGMwAAAAMwapMh8TFxWlzq73yXn31VS9WA5TNo48+qs1XrFhRwZXcWHR0tDafOnWqNr9y5Yo2X7ZsmTZfvny5NrdalWnlzTff1OZPPvmkNr98+bKt4wP+5IEHHtDma9eureBKzMYVMwAAAEMwmAEAABiCwQwAAMAQDGYAAACGYDADAAAwBKsybWrdurU2X7BggTa32ivP6jiAL3Xu3NmR4+Tk5GjzlJQUR47fv39/bX7bbbdp88cee8xWbtdbb72lzX//+99rc1Zfoipq0aKFr0vwC1wxAwAAMASDGQAAgCEYzAAAAAzBYAYAAGAIBjMAAABDsCrTpp49e2pzqz0xrXzwwQdOlAOUSZcuXbS53b0gT506pc3Hjx+vzd977z1bx7dSt25dbW61KtMpq1ev1uZPPfWUNr9w4YI3ywH8SkhIiDZv0qSJNj9y5Ij3ijEYV8wAAAAMwWAGAABgCAYzAAAAQzCYAQAAGILBDAAAwBCsyrQwZMgQbT5//nxtbrUn5ubNm7X5li1bylYY4IDo6GhtHhwcbOs4c+bM0eZfffWVNm/cuLGt41vVed9999k6jl1We1+y+hIoO6vV1HfccYc2Z1UmAAAAfIrBDAAAwBAMZgAAAIZgMAMAADAEgxkAAIAhWJVpwWqVldWqsi+++EKbP/30047VBDjlmWeeceQ4CQkJtvLmzZs7cl5vy8jI0OasvgR+dvnyZV+XUClxxQwAAMAQDGYAAACGYDADAAAwBIMZAACAIRjMAAAADMGqTAt298RMT0+3lQO+9Omnn2rz9u3b2zqOaassv/vuO21er149bV6nTh1tPmvWLG3++eefa/OtW7eWWhtQ2bz44ovaPCkpSZtXr17dm+VUGlwxAwAAMASDGQAAgCEYzAAAAAzBYAYAAGAIBjMAAABDVPlVmQsXLtTmt912mza32ivvueeec6wmwNtmz55t6/5dunTxUiU3dvz4cW2emJiozX/44QdtvmbNGm3et29fbV6zZk1t/sgjj2hzVmUCpbP6rQZwxxUzAAAAQzCYAQAAGILBDAAAwBAMZgAAAIZgMAMAADBElV+VGRsbq80/+OADbb5lyxZtzp6Y8Ce5ubnafNKkSRVcScWYOHGiNt+8ebM279q1qzfLAQBLXDEDAAAwBIMZAACAIRjMAAAADMFgBgAAYAgGMwAAAEO4lAebV+Xm5kp4eHhF1AOUSU5OjoSFhfm6DFvoK5iOvkJZvPrqq9rcanX0rl27tPmAAQMcq8kkpfUVV8wAAAAMwWAGAABgCAYzAAAAQzCYAQAAGILBDAAAwBBVfq9MAADgnJiYGFv3b9CggZcq8U9cMQMAADAEgxkAAIAhGMwAAAAMwWAGAABgCAYzAAAAQ7AqEwAAOCY5OVmb33vvvdp89erV3izH73DFDAAAwBAMZgAAAIZgMAMAADAEgxkAAIAhGMwAAAAMwapMAADgmB07dmjzgACuBXmC7xIAAIAhGMwAAAAMwWAGAABgCAYzAAAAQ3g0mCmlvF0HUC7++Br1x5pRtfjja9Qfa0bVUtpr1KPBLC8vz5FiAG/xx9eoP9aMqsUfX6P+WDOqltJeoy7lwY8XhYWFkpWVJaGhoeJyuRwrDigvpZTk5eVJdHS03y3Fpq9gKvoKcJ6nfeXRYAYAAADv868fhQAAACoxBjMAAABDMJgBAAAYgsEMAADAEAxmAAAAhmAwAwAAMASDGQAAgCH+D8K+Ex1/NOreAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the network.  This is a more typical way to define a network than the sequential structure.  We define a class for the network, and define the parameters in the constructor.  Then we use a function called forward to actually run the network.  It's easy to see how you might use residual connections in this format."
      ],
      "metadata": {
        "id": "_sFvRDGrl4qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # 1. First convolution layer: 1 input channel, 10 output channels, kernel size 5\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "\n",
        "        # 2. Max pooling layer over a 2x2 area (for down-sampling)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # 4. Second convolution layer: 10 input channels, 20 output channels, kernel size 5\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "\n",
        "        # 5. 2D Dropout layer to reduce overfitting\n",
        "        self.drop = nn.Dropout2d()\n",
        "\n",
        "        # 9. Fully connected layer mapping from (320 dimensions here) to 50\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "\n",
        "        # 11. Fully connected layer mapping from 50 to 10 (output classes)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1. Convolution -> 3. ReLU -> 2. Max Pooling\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "\n",
        "        # 4. Second Convolution -> 7. ReLU -> 6. Max Pooling\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "\n",
        "        # 5. Dropout for regularization\n",
        "        x = self.drop(x)\n",
        "\n",
        "        # 8. Flattening the tensor for the fully connected layers\n",
        "        x = x.view(-1, 320)  # Flattening the tensor to match input of fc1\n",
        "\n",
        "        # 9. Fully connected layer -> 10. ReLU\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        # 11. Second fully connected layer\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # 12. Softmax activation for output layer\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "EQkvw2KOPVl7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# He initialization of weights\n",
        "def weights_init(layer_in):\n",
        "  if isinstance(layer_in, nn.Linear):\n",
        "    nn.init.kaiming_uniform_(layer_in.weight)\n",
        "    layer_in.bias.data.fill_(0.0)"
      ],
      "metadata": {
        "id": "qWZtkCZcU_dg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create network\n",
        "model = Net()\n",
        "# Initialize model weights\n",
        "model.apply(weights_init)\n",
        "# Define optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
      ],
      "metadata": {
        "id": "FslroPJJffrh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main training routine\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  # Get each\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = F.nll_loss(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # Store results\n",
        "    if batch_idx % 10 == 0:\n",
        "      print('Train Epoch: {} [{}/{}]\\tLoss: {:.6f}'.format(\n",
        "        epoch, batch_idx * len(data), len(train_loader.dataset), loss.item()))"
      ],
      "metadata": {
        "id": "xKQd9PzkQ766"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run on test data\n",
        "def test():\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      output = model(data)\n",
        "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "Byn-f7qWRLxX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get initial performance\n",
        "test()\n",
        "# Train for three epochs\n",
        "n_epochs = 3\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "metadata": {
        "id": "YgLaex1pfhqz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dafd5b0-2431-4f36-ece7-dabc4fd7860b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Avg. loss: 2.3960, Accuracy: 992/10000 (10%)\n",
            "\n",
            "Train Epoch: 1 [0/60000]\tLoss: 2.462214\n",
            "Train Epoch: 1 [640/60000]\tLoss: 2.236007\n",
            "Train Epoch: 1 [1280/60000]\tLoss: 2.137291\n",
            "Train Epoch: 1 [1920/60000]\tLoss: 2.028086\n",
            "Train Epoch: 1 [2560/60000]\tLoss: 2.012391\n",
            "Train Epoch: 1 [3200/60000]\tLoss: 1.759601\n",
            "Train Epoch: 1 [3840/60000]\tLoss: 1.682634\n",
            "Train Epoch: 1 [4480/60000]\tLoss: 1.357158\n",
            "Train Epoch: 1 [5120/60000]\tLoss: 1.253560\n",
            "Train Epoch: 1 [5760/60000]\tLoss: 1.308620\n",
            "Train Epoch: 1 [6400/60000]\tLoss: 0.910074\n",
            "Train Epoch: 1 [7040/60000]\tLoss: 0.832123\n",
            "Train Epoch: 1 [7680/60000]\tLoss: 0.723807\n",
            "Train Epoch: 1 [8320/60000]\tLoss: 0.777384\n",
            "Train Epoch: 1 [8960/60000]\tLoss: 0.698991\n",
            "Train Epoch: 1 [9600/60000]\tLoss: 0.933884\n",
            "Train Epoch: 1 [10240/60000]\tLoss: 0.659414\n",
            "Train Epoch: 1 [10880/60000]\tLoss: 0.933144\n",
            "Train Epoch: 1 [11520/60000]\tLoss: 0.853056\n",
            "Train Epoch: 1 [12160/60000]\tLoss: 0.468219\n",
            "Train Epoch: 1 [12800/60000]\tLoss: 0.676275\n",
            "Train Epoch: 1 [13440/60000]\tLoss: 0.623728\n",
            "Train Epoch: 1 [14080/60000]\tLoss: 0.525894\n",
            "Train Epoch: 1 [14720/60000]\tLoss: 0.552680\n",
            "Train Epoch: 1 [15360/60000]\tLoss: 0.574233\n",
            "Train Epoch: 1 [16000/60000]\tLoss: 0.414726\n",
            "Train Epoch: 1 [16640/60000]\tLoss: 0.336699\n",
            "Train Epoch: 1 [17280/60000]\tLoss: 0.452714\n",
            "Train Epoch: 1 [17920/60000]\tLoss: 0.228482\n",
            "Train Epoch: 1 [18560/60000]\tLoss: 0.324174\n",
            "Train Epoch: 1 [19200/60000]\tLoss: 0.557764\n",
            "Train Epoch: 1 [19840/60000]\tLoss: 0.456604\n",
            "Train Epoch: 1 [20480/60000]\tLoss: 0.401745\n",
            "Train Epoch: 1 [21120/60000]\tLoss: 0.472423\n",
            "Train Epoch: 1 [21760/60000]\tLoss: 0.413321\n",
            "Train Epoch: 1 [22400/60000]\tLoss: 0.350744\n",
            "Train Epoch: 1 [23040/60000]\tLoss: 0.470763\n",
            "Train Epoch: 1 [23680/60000]\tLoss: 0.535537\n",
            "Train Epoch: 1 [24320/60000]\tLoss: 0.340954\n",
            "Train Epoch: 1 [24960/60000]\tLoss: 0.351802\n",
            "Train Epoch: 1 [25600/60000]\tLoss: 0.283666\n",
            "Train Epoch: 1 [26240/60000]\tLoss: 0.479288\n",
            "Train Epoch: 1 [26880/60000]\tLoss: 0.492918\n",
            "Train Epoch: 1 [27520/60000]\tLoss: 0.398414\n",
            "Train Epoch: 1 [28160/60000]\tLoss: 0.313578\n",
            "Train Epoch: 1 [28800/60000]\tLoss: 0.242666\n",
            "Train Epoch: 1 [29440/60000]\tLoss: 0.197519\n",
            "Train Epoch: 1 [30080/60000]\tLoss: 0.271924\n",
            "Train Epoch: 1 [30720/60000]\tLoss: 0.377380\n",
            "Train Epoch: 1 [31360/60000]\tLoss: 0.420175\n",
            "Train Epoch: 1 [32000/60000]\tLoss: 0.162656\n",
            "Train Epoch: 1 [32640/60000]\tLoss: 0.126344\n",
            "Train Epoch: 1 [33280/60000]\tLoss: 0.619292\n",
            "Train Epoch: 1 [33920/60000]\tLoss: 0.429886\n",
            "Train Epoch: 1 [34560/60000]\tLoss: 0.152992\n",
            "Train Epoch: 1 [35200/60000]\tLoss: 0.318389\n",
            "Train Epoch: 1 [35840/60000]\tLoss: 0.133132\n",
            "Train Epoch: 1 [36480/60000]\tLoss: 0.386030\n",
            "Train Epoch: 1 [37120/60000]\tLoss: 0.236246\n",
            "Train Epoch: 1 [37760/60000]\tLoss: 0.275249\n",
            "Train Epoch: 1 [38400/60000]\tLoss: 0.401994\n",
            "Train Epoch: 1 [39040/60000]\tLoss: 0.299304\n",
            "Train Epoch: 1 [39680/60000]\tLoss: 0.484142\n",
            "Train Epoch: 1 [40320/60000]\tLoss: 0.288294\n",
            "Train Epoch: 1 [40960/60000]\tLoss: 0.283020\n",
            "Train Epoch: 1 [41600/60000]\tLoss: 0.287029\n",
            "Train Epoch: 1 [42240/60000]\tLoss: 0.238162\n",
            "Train Epoch: 1 [42880/60000]\tLoss: 0.192686\n",
            "Train Epoch: 1 [43520/60000]\tLoss: 0.379188\n",
            "Train Epoch: 1 [44160/60000]\tLoss: 0.310223\n",
            "Train Epoch: 1 [44800/60000]\tLoss: 0.364854\n",
            "Train Epoch: 1 [45440/60000]\tLoss: 0.248801\n",
            "Train Epoch: 1 [46080/60000]\tLoss: 0.291205\n",
            "Train Epoch: 1 [46720/60000]\tLoss: 0.456710\n",
            "Train Epoch: 1 [47360/60000]\tLoss: 0.480596\n",
            "Train Epoch: 1 [48000/60000]\tLoss: 0.340220\n",
            "Train Epoch: 1 [48640/60000]\tLoss: 0.334147\n",
            "Train Epoch: 1 [49280/60000]\tLoss: 0.349268\n",
            "Train Epoch: 1 [49920/60000]\tLoss: 0.360887\n",
            "Train Epoch: 1 [50560/60000]\tLoss: 0.429287\n",
            "Train Epoch: 1 [51200/60000]\tLoss: 0.265427\n",
            "Train Epoch: 1 [51840/60000]\tLoss: 0.409141\n",
            "Train Epoch: 1 [52480/60000]\tLoss: 0.355606\n",
            "Train Epoch: 1 [53120/60000]\tLoss: 0.310038\n",
            "Train Epoch: 1 [53760/60000]\tLoss: 0.405832\n",
            "Train Epoch: 1 [54400/60000]\tLoss: 0.156846\n",
            "Train Epoch: 1 [55040/60000]\tLoss: 0.281551\n",
            "Train Epoch: 1 [55680/60000]\tLoss: 0.160042\n",
            "Train Epoch: 1 [56320/60000]\tLoss: 0.225535\n",
            "Train Epoch: 1 [56960/60000]\tLoss: 0.298267\n",
            "Train Epoch: 1 [57600/60000]\tLoss: 0.224052\n",
            "Train Epoch: 1 [58240/60000]\tLoss: 0.311639\n",
            "Train Epoch: 1 [58880/60000]\tLoss: 0.170525\n",
            "Train Epoch: 1 [59520/60000]\tLoss: 0.284532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run network on data we got before and show predictions\n",
        "output = model(example_data)\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(10):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Prediction: {}\".format(\n",
        "    output.data.max(1, keepdim=True)[1][i].item()))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o7fRUAy9Se1B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}