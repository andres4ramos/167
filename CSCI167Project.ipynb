{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "64zoTYhXMHHA"
      ],
      "mount_file_id": "17lFUdEEc5tQ27PrZmrnhSCGw1L8g4bw8",
      "authorship_tag": "ABX9TyP8B/VvtkVyNRSUitlv8Tci",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andres4ramos/167/blob/main/CSCI167Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SMS Spam Classification with PyTorch\n",
        "Overview:\n",
        "This project focuses on building a neural network to classify SMS messages as spam or ham (non-spam). Using a PyTorch-based Multi-Layer Perceptron (MLP), we preprocess the text data, train the model, and analyze its performance.\n",
        "\n",
        "Importing Libraries:\n",
        "\n"
      ],
      "metadata": {
        "id": "3OpuFjEfjqLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch  #PyTorch library for building and training neural networks.\n",
        "import torch.nn as nn  # Submodule for defining neural network layers.\n",
        "import torch.optim as optim  # Optimizer module for gradient-based optimization.\n",
        "import matplotlib.pyplot as plt  # Visualization library for creating plots.\n",
        "import pandas as pd  # Data manipulation and analysis library.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # Converts text to numerical features using TF-IDF.\n",
        "from sklearn.model_selection import train_test_split  # Splits data into training and testing sets.\n",
        "from sklearn.metrics import classification_report, confusion_matrix  # For evaluating model performance.\n",
        "import seaborn as sns  # Visualization library for enhanced plots\n"
      ],
      "metadata": {
        "id": "LUI-KWxrW7UW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "997aea26-38ed-48dc-fca2-17391d9a6ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'torch' has no attribute 'version' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-adee6c6bfefe>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m  \u001b[0;31m#PyTorch library for building and training neural networks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m  \u001b[0;31m# Submodule for defining neural network layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m  \u001b[0;31m# Optimizer module for gradient-based optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m  \u001b[0;31m# Visualization library for creating plots.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m  \u001b[0;31m# Data manipulation and analysis library.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2475\u001b[0;31m from torch import (\n\u001b[0m\u001b[1;32m   2476\u001b[0m     \u001b[0mexport\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdynamic_shapes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConstraint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mShapesCollection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexported_program\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExportedProgram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleCallEntry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleCallSignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgraph_signature\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExportBackwardSignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExportGraphSignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/export/dynamic_shapes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexported_program\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExportedProgram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_higher_order_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograd_not_implemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_library\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_class_registry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFakeScriptObject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfirst_call_function_nn_module_stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_higher_order_ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_higher_order_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m from torch._higher_order_ops.flex_attention import (\n\u001b[1;32m      3\u001b[0m     \u001b[0mflex_attention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mflex_attention_backward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_higher_order_ops/cond.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_subclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDispatchKey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_subclasses/functional_tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inductor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minductor_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_functionalization_reapply_views_tls\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_reapply_views\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# use fx aot graph codegen cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m fx_graph_cache = (\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TORCHINDUCTOR_FX_GRAPH_CACHE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_fbcode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_inductor/config.py\u001b[0m in \u001b[0;36mis_fbcode\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_fbcode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"git_version\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torch' has no attribute 'version' (most likely due to a circular import)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next,  we clean up the data to make it suitable for training the model that to accurately classify messages as spam or ham. The steps involved include:\n",
        "\n",
        "Removes unnecessary columns: Deletes columns that aren't needed for analysis.\n",
        "\n",
        "Renames columns: Gives the columns clearer names.\n",
        "\n",
        "Removes duplicates: Deletes any duplicate messages.\n",
        "\n",
        "Standardizes text: Converts all text to lowercase for consistency.\n",
        "\n",
        "Encodes the target variable: Replaces \"ham\" and \"spam\" with numbers (0 and 1) for machine learning.\n"
      ],
      "metadata": {
        "id": "nyT0AJTwJB4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('spamdataset.csv', encoding='latin1')  # Update the path to your dataset\n",
        "\n",
        "# Step 1: Drop unnecessary columns\n",
        "columns_to_drop = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\n",
        "data.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "# Step 2: Rename columns for clarity\n",
        "data.rename(columns={'v1': 'target', 'v2': 'text'}, inplace=True)\n",
        "\n",
        "# Step 3: Check and remove duplicate rows\n",
        "data = data.drop_duplicates()\n",
        "\n",
        "# Step 4: Standardize text data (convert to lowercase)\n",
        "data['text'] = data['text'].str.lower()\n",
        "\n",
        "\n",
        "# Save the cleaned dataset for future use\n",
        "data.to_csv('cleaned_spam_dataset.csv', index=False)\n"
      ],
      "metadata": {
        "id": "lRCGFOLOvaB-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "d02a8aab-a235-45c8-99be-a799df9f6719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-50f980a83445>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spamdataset.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update the path to your dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Step 1: Drop unnecessary columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcolumns_to_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Unnamed: 3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Unnamed: 4'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This segment cleans and visualizes the dataset's label distribution:\n",
        "\n",
        "Data Cleaning:\n",
        "\n",
        "Removes unnecessary columns and duplicate rows.\n",
        "Renames columns for clarity and standardizes text to lowercase.\n",
        "Encodes labels (ham = 0, spam = 1) for analysis.\n",
        "Label Distribution:\n",
        "\n",
        "Calculates the count and percentage of spam and ham messages.\n",
        "Identifies potential class imbalances.\n",
        "Visualization:\n",
        "\n",
        "Generates a pie chart displaying the proportion of ham and spam messages with counts and percentages for clear insights.\n",
        "Importance:\n",
        "Highlights dataset class distribution, aiding in understanding potential imbalances.\n",
        "Ensures clean data for accurate model training.\n",
        "Provides a clear, intuitive visual summary."
      ],
      "metadata": {
        "id": "XUuGVuuGhePY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('spamdataset.csv', encoding='latin1')  # Update the path to your dataset\n",
        "columns_to_drop = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\n",
        "data.drop(columns=columns_to_drop, inplace=True)\n",
        "data.rename(columns={'v1': 'target', 'v2': 'text'}, inplace=True)\n",
        "data = data.drop_duplicates()\n",
        "data['text'] = data['text'].str.lower()\n",
        "label_mapping = {'ham': 0, 'spam': 1}\n",
        "data['target'] = data['target'].map(label_mapping)\n",
        "\n",
        "# Count the occurrences of spam and ham\n",
        "label_counts = spam_data['label'].value_counts()\n",
        "labels = ['Ham', 'Spam']  # 0 = Ham, 1 = Spam\n",
        "sizes = label_counts.values  # Counts of each label\n",
        "percentages = (sizes / sizes.sum()) * 100  # Calculate percentages\n",
        "colors = ['#8FD9A8', '#FF6F61']  # Colors for ham and spam\n",
        "\n",
        "# Create the pie chart\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(\n",
        "    sizes,\n",
        "    labels=[f'{label} ({count})' for label, count in zip(labels, sizes)],  # Show counts next to labels\n",
        "    colors=colors,\n",
        "    autopct=lambda p: f'{p:.1f}%',  # Show percentages on slices\n",
        "    startangle=90,\n",
        "    explode=(0, 0.1)  # Slightly separate the spam slice\n",
        ")\n",
        "plt.title('Proportions of Ham vs Spam Messages')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "cPQhYys6Kbjp",
        "outputId": "168271b5-09ae-4dfe-cce5-81f8aa4d9c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9dcb8284c8bd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spamdataset.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update the path to your dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcolumns_to_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Unnamed: 3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Unnamed: 4'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns_to_drop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'v1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v2'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This process converts text into numerical features for machine learning by focusing on:\n",
        "\n",
        "Term Frequency (TF): How often a word appears in a message.\n",
        "\n",
        "Inverse Document Frequency (IDF): Highlights unique words while reducing the weight of common words (e.g., \"the,\" \"and\").\n",
        "\n",
        "Key Details:\n",
        "\n",
        "Max Features: Limits to the top 1000 important words for efficiency and relevance.\n",
        "\n",
        "Stop Words: Removes common words that don’t aid classification.\n",
        "\n",
        "Output: Creates a matrix where rows represent messages and columns represent word features.\n",
        "\n",
        "The data is split into training (80%) and testing (20%) sets and converted to PyTorch tensors for compatibility with the model. This step ensures the model trains effectively on numerical input."
      ],
      "metadata": {
        "id": "64zoTYhXMHHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to TF-IDF features with 1000 features\n",
        "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')  # Limit to 1000 features\n",
        "X = vectorizer.fit_transform(spam_data['text']).toarray()\n",
        "y = spam_data['label'].values\n",
        "\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert data to PyTorch tensors for model training\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Display summary statistics for TF-IDF values\n",
        "print(f\"TF-IDF Matrix - Min: {X.min():.4f}, Max: {X.max():.4f}, Mean: {X.mean():.4f}\")\n",
        "print(f\"Sparsity: {100 * (1 - (X > 0).sum() / X.size):.2f}% (percentage of zero values)\")\n",
        "\n",
        "# Get the top 1000 features (words) selected by TF-IDF\n",
        "top_words = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Print the top 20 words (for example)\n",
        "print(\"Top 20 Words Selected by TF-IDF:\")\n",
        "print(top_words[:20])  # Adjust the range as needed\n",
        "\n"
      ],
      "metadata": {
        "id": "D4RyEP7GW7hd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "00523660-17c3-4141-a0b5-63adb0aeeb46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'TfidfVectorizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a2f363706c73>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert text to TF-IDF features with 1000 features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Limit to 1000 features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspam_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspam_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TfidfVectorizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SpamClassifier Model\n",
        "Here, we define a neural network (MLP) to classify SMS messages as spam or ham. It processes numerical features derived from TF-IDF vectorization through three fully connected layers. Here's how it works:\n",
        "\n",
        "###Layers:\n",
        "The input features are passed through two hidden layers, reducing the dimensions step-by-step.\n",
        "The final layer outputs a single value, representing the probability of the message being spam.\n",
        "###Activations:\n",
        "\n",
        "ReLU Activation: Adds non-linearity, helping the model learn complex relationships in the data.\n",
        "Sigmoid Activation: Converts the final output into a probability between 0 and 1.\n",
        "###Purpose:\n",
        "\n",
        "The model learns patterns in the text data that distinguish spam from ham and outputs a clear probability for classification."
      ],
      "metadata": {
        "id": "s2Xnd2z_NAhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the SpamClassifier model\n",
        "class SpamClassifier(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SpamClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)  # Input layer to hidden layer 1\n",
        "        self.fc2 = nn.Linear(128, 64)        # Hidden layer 1 to hidden layer 2\n",
        "        self.fc3 = nn.Linear(64, 1)          # Hidden layer 2 to output layer\n",
        "        self.relu = nn.ReLU()                # ReLU activation for non-linearity\n",
        "        self.sigmoid = nn.Sigmoid()          # Sigmoid activation for probability output\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.sigmoid(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "input_dim = X_train.shape[1]\n",
        "model = SpamClassifier(input_dim)"
      ],
      "metadata": {
        "id": "cvaN2uguW7jU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "1ba478ce-fc91-443d-b23d-c5082f0a21b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-52ff437107cb>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Instantiate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpamClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loss Function and Optimizer\n",
        "Binary Cross-Entropy Loss (BCELoss):\n",
        "\n",
        "Used for binary classification tasks.\n",
        "Calculates the difference between predicted probabilities (e.g., spam/ham) and true labels.\n",
        "Ensures the model penalizes incorrect predictions, helping it focus on reducing classification errors.\n",
        "Adam Optimizer:\n",
        "\n",
        "An advanced optimization algorithm combining momentum and adaptive learning rates.\n",
        "Efficiently updates model weights to minimize the loss function.\n",
        "Adjusts learning rates dynamically, ensuring faster convergence and stability during training.\n"
      ],
      "metadata": {
        "id": "CY6z_kMDUXxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "VZcydq3JW7lR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "fe51b39f-5675-459a-eb35-63e5977477de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-cd00e86fc242>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Binary Cross-Entropy Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training: The model learns by processing data in mini-batches of size 32 for efficiency.\n",
        "\n",
        "Loss Calculation: Measures prediction error using BCELoss (Binary Cross-Entropy).\n",
        "\n",
        "Optimization: Updates weights via backpropagation using the Adam optimizer.\n",
        "\n",
        "Tracking: Saves total loss for each epoch to monitor performance.\n",
        "\n",
        "Visualization: Plotting a graph of loss over epochs to evaluate learning progress."
      ],
      "metadata": {
        "id": "txWjPakrT9Ht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "# To store loss values for visualization\n",
        "epoch_losses = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for i in range(0, X_train_tensor.size(0), batch_size):\n",
        "        # Get mini-batch\n",
        "        X_batch = X_train_tensor[i:i+batch_size]\n",
        "        y_batch = y_train_tensor[i:i+batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # Save epoch loss for visualization\n",
        "    epoch_losses.append(epoch_loss)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(range(1, epochs + 1), epoch_losses, marker='o', label='Training Loss')\n",
        "plt.title('Training Loss Over Epochs', fontsize=14)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Kvb3hxsnfbQT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "2eb12303-f1d1-41b4-c1a4-7cd9c4403fc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-077a4fd3ca08>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluation and Visualization\n",
        "Evaluation Mode: Switches the model to testing mode to ensure gradients aren’t calculated, improving efficiency.\n",
        "\n",
        "Predictions: Predicts probabilities for test data and converts them into binary classifications (spam=1, ham=0) based on a threshold of 0.5.\n",
        "\n",
        "Metrics: Calculates essential metrics like accuracy, precision, and recall to assess the model's ability to correctly classify messages.\n",
        "\n",
        "Confusion Matrix: Breaks down predictions into True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN) to analyze performance.\n",
        "\n",
        "Visualization: Displays a heatmap of the confusion matrix, including numerical counts, percentages, and labeled components for easy interpretation."
      ],
      "metadata": {
        "id": "ZOHbPzoUYW0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Evaluate the model\n",
        "with torch.no_grad():  # Disable gradient calculations for efficiency\n",
        "    y_pred = model(X_test_tensor)  # Predict probabilities for the test set\n",
        "    y_pred_class = (y_pred > 0.5).float()  # Convert probabilities to binary predictions (spam=1, ham=0)\n",
        "\n",
        "# Generate and print a detailed classification report\n",
        "report = classification_report(\n",
        "    y_test,\n",
        "    y_pred_class.numpy(),\n",
        "    target_names=['Ham', 'Spam'],\n",
        "    digits=4  # Ensure metrics are displayed with higher precision\n",
        ")\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred_class.numpy())\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# Calculate metrics manually\n",
        "TN, FP, FN, TP = cm.ravel()  # Extract confusion matrix values\n",
        "\n",
        "# Accuracy\n",
        "accuracy = (TP + TN) / (TN + FP + FN + TP)\n",
        "print(f\"Accuracy: {accuracy:.4f} ({accuracy * 100:.2f}%)\")\n",
        "\n",
        "# Precision (for Spam)\n",
        "precision_spam = TP / (TP + FP)\n",
        "print(f\"Precision (Spam): {precision_spam:.4f} ({precision_spam * 100:.2f}%)\")\n",
        "\n",
        "# Recall (for Spam)\n",
        "recall_spam = TP / (TP + FN)\n",
        "print(f\"Recall (Spam): {recall_spam:.4f} ({recall_spam * 100:.2f}%)\")\n",
        "\n",
        "# Visualize the confusion matrix with additional details\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Calculate percentages for the confusion matrix\n",
        "cm_sum = np.sum(cm)\n",
        "cm_percent = cm / cm_sum * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
        "plt.xlabel('Predicted Labels', fontsize=12)\n",
        "plt.ylabel('True Labels', fontsize=12)\n",
        "plt.title('Confusion Matrix', fontsize=14)\n",
        "\n",
        "labels = [['TN', 'FP'], ['FN', 'TP']]\n",
        "for i in range(2):  # Rows\n",
        "    for j in range(2):  # Columns\n",
        "        # Add TN, FP, FN, TP labels below the main numbers\n",
        "        plt.text(j + 0.5, i + 0.6, f'{labels[i][j]}', ha='center', va='center', fontsize=10, color='black')\n",
        "        # Add percentages slightly below the labels\n",
        "        plt.text(j + 0.5, i + 0.8, f'{cm_percent[i, j]:.1f}%', ha='center', va='center', fontsize=10, color='black')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qSeEWriTfbSd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "bad8913f-10d4-4c26-bbf5-7e4e8d6d9cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-ada283b0bd3a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Set the model to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Disable gradient calculations for efficiency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}